{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"zi8Hg884KmQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nW_gFGVf9YOZ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import math\n","import csv\n","import random\n","import itertools\n","import time\n","import seaborn as sns\n","import warnings\n","from matplotlib.ticker import MultipleLocator\n","\n","from collections import Counter\n","from pylab import *\n","from time import gmtime, strftime\n","from datetime import datetime\n","\n","from sklearn.svm import SVR\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error \n","from sklearn.model_selection import GridSearchCV\n","from sklearn.impute import KNNImputer\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn import svm, datasets\n","from sklearn.metrics import plot_confusion_matrix\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import Lasso\n","from sklearn.pipeline import Pipeline\n","from sklearn.datasets import make_regression\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.feature_selection import f_regression\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score"]},{"cell_type":"markdown","metadata":{"id":"wVhmKzSw9YOc"},"source":["<h1>0. Configuration</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNVQC7n_9YOd"},"outputs":[],"source":["DATA_FILE_LOCATION = ''\n","#Replace this with symbol or value that represents missing value in the data. E.g. '-', 0 or -1.0 etc\n","MISSING_VALUES_PLACEHOLDER = -1 \n","OUTCOME_COL_NAME = 'tag_gadel' # Age at delivery\n","\n","SHOW_VISUALISATIONS = True\n","COLORS = ['#003f5c', '#f95d6a','#6a9e3c','#f2975a', '#a05195', '#2f4b7c', '#665191', '#d45087', '#ffa600']"]},{"cell_type":"markdown","metadata":{"id":"k4kdp7gR9YOe"},"source":["<h1>1. Loading raw data into a dataframe</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3hV_6Z9i9YOf"},"outputs":[],"source":["def load_medical_data(file_name):\n","    return pd.read_csv(file_name, header = 'infer')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jeqmAPb9YOf"},"outputs":[],"source":["raw_data = load_medical_data(DATA_FILE_LOCATION)"]},{"cell_type":"markdown","metadata":{"id":"8pA6IMB89YOg"},"source":["<h1>2. Data preparation for preprocessing</h1>"]},{"cell_type":"markdown","metadata":{"id":"IbN05aG49YOg"},"source":["<h2>2.1 Replace missing values with NaNs</h2>\n","<p>This is needed for proper handling of missing values and to allow the code and other functions to run. Missing value placeholder can be tuned with configuration property <i><b>MISSING_VALUES_PLACEHOLDER</b></i>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fsp4vN_9YOh"},"outputs":[],"source":["def replace_missing_values(dataframe):\n","    return dataframe.replace(MISSING_VALUES_PLACEHOLDER, np.nan)"]},{"cell_type":"markdown","metadata":{"id":"d4C-GA209YOh"},"source":["<h2>2.2 Remove all rows where outcome (age at delivery) is missing</h2>\n","<p>Instances without age at delivery provide no useful information for the ML model and therefore can be deleted</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCjQXf8v9YOh"},"outputs":[],"source":["def remove_rows_without_outcome(dataframe):\n","    dataframe = dataframe.copy()\n","    return dataframe.dropna(subset=[OUTCOME_COL_NAME]).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"thSCG7kk9YOj"},"source":["<h2>2.3 Remove all columns that are completely empty (all values are NaN)</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3o6DjDr-9YOj"},"outputs":[],"source":["def remove_cols_with_no_data(dataframe):\n","    dataframe = dataframe.copy()\n","    dataframe = dataframe.dropna(axis='columns', how='all')\n","    return dataframe"]},{"cell_type":"markdown","source":["<h2>2.4 Remove all rows that are not from a 3T scanner (in this case label = 1).</h2>"],"metadata":{"id":"juKzJ5HLa-6R"}},{"cell_type":"code","source":["def remove_rows_no_3T(dataframe):\n","    dataframe = dataframe.copy()\n","    dataframe = dataframe.loc[dataframe['tag_scanner'] == 1]\n","    return dataframe"],"metadata":{"id":"OGkF7YzBa9-W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p0WQxNj79YOj"},"source":["<h2>2.4 Add category columns</h2>\n","<h3>2.4.1 Add Binary and 4-category columns</h3>\n","<p>Raw dataset contains the week of delivery as an outcome (GA at birth (later named just GA)). Based on this week, additional categorical columns will be added. More specifically two new columns:</p>\n","<ul>\n","    <li><b>ga_delivery_binary_category</b> - Has values 0 and 1, where 0 means that <b>GA>=37</b> and 1 means that <b>GA&lt;37</b></li>\n","    <li><b>ga_delivery_4_category</b> - Has values 0,1,2 and 3, where 0 means that <b>GA>=37</b>, 1 means that <b>32&lt;=GA&lt;37</b>, 2 means <b>28&lt;=GA&lt;32</b> and 3 means <b>GA&lt;28</b></li>\n","</ul>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7g-Cnoqk9YOj"},"outputs":[],"source":["def divide_to_categories(dataframe, \n","                         columns_to_categorize = ['tag_gadel'], \n","                         categorized_columns_names = ['ga_delivery']):\n","    CATEGORY_TERM = 0               # Term baby GA >= 37 \n","    CATEGORY_PRETERM = 1            # Preterm baby GA < 37\n","\n","    CATEGORY_LATE_PRETERM = 1       # Late preterm 32 <= GA < 37\n","    CATEGORY_VERY_PRETERM = 2       # Very preterm 28 <= GA < 32\n","    CATEGORY_EXTREMELY_PRETERM = 3  # Extremely preterm GA < 28 \n","    \n","    dataframe = dataframe.copy()\n","    \n","    for col_id, column_to_categorize in enumerate(columns_to_categorize):\n","        GA_delivery_array = dataframe[column_to_categorize]\n","        nr_of_patients = GA_delivery_array.size\n","        outcome_2_categories = []\n","        outcome_4_categories = []\n","\n","        for i in range(0, nr_of_patients):\n","            if (GA_delivery_array[i] < 28):\n","                outcome_4_categories.append(3)\n","                outcome_2_categories.append(1)\n","            elif (GA_delivery_array[i] >= 28 and GA_delivery_array[i] < 32):\n","                outcome_4_categories.append(2)\n","                outcome_2_categories.append(1)\n","            elif (GA_delivery_array[i] >= 32 and GA_delivery_array[i] < 37): \n","                outcome_4_categories.append(1)\n","                outcome_2_categories.append(1)\n","            else:\n","                outcome_4_categories.append(0)\n","                outcome_2_categories.append(0)\n","\n","        dataframe_4_categories = pd.DataFrame(outcome_4_categories)\n","        dataframe_4_categories.columns = [categorized_columns_names[col_id] + '_4_category']\n","\n","        dataframe_2_categories = pd.DataFrame(outcome_2_categories)\n","        dataframe_2_categories.columns = [categorized_columns_names[col_id] + '_binary_category']\n","\n","        dataframe = pd.concat([dataframe, dataframe_4_categories, dataframe_2_categories], axis = 1, join = 'inner')\n","    \n","    return dataframe"]},{"cell_type":"markdown","metadata":{"id":"fkjM5kSA9YOk"},"source":["<h3>2.4.2 Add 35_37-cohort category</h3>\n","<p>Additionally, a category taking into account the cohort and GA at birth is added.</p>\n","<ul>\n","    <li><b>35_and_37_category</b> - Has values 0,1 and 2, where 0 means that <b>GA>=37 and cohort == 99</b>, 2 means that <b>GA&lt;35</b>, 1 is every other sample in between\n","</ul>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkfwQyUX9YOk"},"outputs":[],"source":["def add_35_and_37_category(dataframe):\n","    outcome_categories_35_and_37 = []\n","    \n","    ga_delivery_column = dataframe['tag_gadel']\n","    tech_cohort_column = dataframe['tag_typ']\n","    nr_of_patients = ga_delivery_column.size\n","    \n","    for i in range(0, nr_of_patients):\n","        if (ga_delivery_column[i] >= 37 and tech_cohort_column[i] == 99):\n","            outcome_categories_35_and_37.append(0)\n","        elif (ga_delivery_column[i] <= 35):\n","            outcome_categories_35_and_37.append(2)\n","        else:\n","            outcome_categories_35_and_37.append(1)\n","\n","    dataframe_35_and_37 = pd.DataFrame(outcome_categories_35_and_37)\n","    dataframe_35_and_37.columns = ['35_and_37_category']\n","\n","    return pd.concat([dataframe, dataframe_35_and_37], axis = 1, join = 'inner')"]},{"cell_type":"markdown","metadata":{"id":"scN8X9099YOl"},"source":["<h2>2.6 Finally apply all data preparation steps</h2>\n","<p>Function <b>get_data()</b> returns a dataframe that has all data preparation steps already applied</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3k5ZHvjS9YOl"},"outputs":[],"source":["_data = replace_missing_values(raw_data)\n","_data = remove_rows_without_outcome(_data)\n","_data = remove_cols_with_no_data(_data)\n","_data = divide_to_categories(_data)\n","_data = add_35_and_37_category(_data)\n","_data = remove_rows_no_3T(_data)\n","\n","\n","\n","def get_data():\n","    return _data.copy()"]},{"cell_type":"markdown","metadata":{"id":"wjMgGVNr9YOl"},"source":["<h1>3. Data preprocessing</h1>"]},{"cell_type":"markdown","metadata":{"id":"K8JZB1ui9YOl"},"source":["<h2>3.1 Find z-Scores for specified columns</h2>"]},{"cell_type":"markdown","metadata":{"id":"L4QO83fP9YOm"},"source":["<h3>3.1.1 Helper functions for Z-Score</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4OM8THp29YOn"},"outputs":[],"source":["# Returns only specified columns and drops all rows where at least one of the columns has a NaN value in that row\n","def get_columns_and_drop_nan_rows(dataframe, list_of_features):\n","    for feature in list_of_features:\n","        dataframe = dataframe.dropna(subset = [feature]) \n","    dataframe = dataframe[dataframe.columns.intersection(list_of_features)]\n","    return dataframe\n","\n","# Takes in list of column names and converts them to z score column names. \n","# E.g ['col_1', 'col_2'] -> ['col_1_z_score', 'col_2_z_score']\n","def convert_to_zscore_column_names(non_zscore_column_names):\n","    z_names = []\n","    for col in non_zscore_column_names:\n","        z_names.append(col + '_z_score')\n","        \n","    return z_names\n","\n","def convert_to_zscore_column_names_gu(non_zscore_column_names):\n","    z_names = []\n","    for col in non_zscore_column_names:\n","        z_names.append(col + '_z_score_gu')\n","        \n","    return z_names\n","\n","def convert_to_zscore_column_names_anom(non_zscore_column_names):\n","    z_names = []\n","    for col in non_zscore_column_names:\n","        z_names.append(col + '_z_score_anom')\n","        \n","    return z_names\n","\n","\n","# Feature names\n","ORIGINAL_COL_NAMES = get_data().columns\n","BIRTH_CATEGORIES_4 = ['Term','Late preterm','Very preterm','Extremely preterm']\n","BIRTH_CATEGORIES_2 = ['Term', 'Preterm']\n","\n","MEDICALLY_IRRELEVANT_FEATURE_NAMES = ['tag_ethnicity', 'tag_scanner', 'tag_patient', '[95]', '[96]', '[97]', 'tag_missing_info', 'tag_complete_id', 'tag_study_id', 'rr', 'rr.2',]\n","OUTCOME_FEATURE_NAMES = ['tag_typ', 'tag_gadel', 'tag_mod', 'tag_bwg', 'tag_bwc', 'tag_hc', 'tag_hcc', 'tag_garom', 'tag_histo_weight', 'tag_histo_mvm', 'tag_histo_fvm', 'tag_histo_chorio', 'tag_apgar5', 'tag_del_bwc', 'ga_delivery_4_category', 'ga_delivery_binary_category', 'tag_cat_norm', '35_and_37_category']\n","NOT_ENOUGH_DATA_FEATURE_NAMES = ['tag_vol_0','tag_vol_1', 'tag_vol_2', 'tag_vol_3', 'tag_vol_4', 'tag_vol_5', 'tag_vol_6', 'tag_vol_7', 'diff_1', 'diff_2', 'diff_3', 'diff_4', 'diff_5', 'diff_6', 'diff_7', 'diff_8', 'diff_9', 'diff_10', 'diff_11', 'lung_t2s_kurt', 'lung_t2s_lacu', 'lung_t2s_mean', 'lung_t2s_skew', 'lung_t2s_vol', 'tag_vol_body', 'tag_anom_cord_ins', 'tag_gu_cord_ins', 'tag_anom_pi_left', 'tag_anom_pi_right', 'tag_cervix_length', 'tag_vol_t2w_complete']\n","\n","#Threshold of <30%, Change Features in each category according to threshold\n","ALL_Z_SCORE_FEATURE_NAMES = ['plac_t2s_kurt', \n","                             'plac_t2s_lacu',\n","                             'plac_t2s_mean',\n","                             'plac_t2s_skew',\n","                             'plac_t2s_vol',\n","                             'tag_cervix_length']\n","\n","\n","ALL_Z_SCORE_FEATURE_NAMES_GU = []\n","\n","ALL_Z_SCORE_FEATURE_NAMES_ANOM = ['tag_anom_ac',\n","                             'tag_anom_bpd',\n","                             'tag_anom_fl',\n","                             'tag_anom_hc',]\n","                            \n","\n","ALL_REGULAR_FEATURE_NAMES = ['tag_age',\n","                             'tag_bmi',\n","                             'tag_loc',\n","                             'tag_sex',\n","                             'tag_parity',\n","                             'tag_diabetes',\n","                             'tag_anom_loc',\n","                             'tag_anom_cord',\n","                             'tag_ivf',\n","                             'tag_smok',\n","                             'tag_prev_ptb']\n","# ALL_FEATURE_NAMES =  convert_to_zscore_column_names(ALL_Z_SCORE_FEATURE_NAMES) + ALL_REGULAR_FEATURE_NAMES\n","ALL_FEATURE_NAMES =  convert_to_zscore_column_names(ALL_Z_SCORE_FEATURE_NAMES) + convert_to_zscore_column_names_gu(ALL_Z_SCORE_FEATURE_NAMES_GU) + convert_to_zscore_column_names_anom(ALL_Z_SCORE_FEATURE_NAMES_ANOM) + ALL_REGULAR_FEATURE_NAMES"]},{"cell_type":"markdown","metadata":{"id":"JnVlreX19YOn"},"source":["<h3>3.1.2 Z-Score Calculation functions</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTLT-Akn9YOn"},"outputs":[],"source":["epsilon = 2.22045e-16\n","def add_column_with_z_score(dataframe, column_name, show_graphs):\n","    dataframe = dataframe.copy()\n","    ga_at_scan_key = 'tag_ga'\n","    ga_at_delivery_key = 'tag_gadel'\n","    tech_cohort_key = 'tag_typ'\n","    \n","    if ga_at_scan_key not in dataframe:\n","        print(\"Dataframe is missing 'tag_ga'(age at scan)\")\n","        return\n","    \n","    # Returns dataframe with Age at scan and specified measurement / feature\n","    relevant_data = get_columns_and_drop_nan_rows(dataframe, [ga_at_scan_key, ga_at_delivery_key, column_name, tech_cohort_key])[[ga_at_scan_key, ga_at_delivery_key, column_name, tech_cohort_key]] \n","    \n","    \n","    X = relevant_data[ga_at_scan_key].to_numpy().reshape(-1, 1)\n","    y = relevant_data[column_name]\n","    \n","    \n","    if show_graphs:\n","        # Plot scatterplot of the specific column vs age at scan\n","        fig, axs = plt.subplots(2, figsize = (20, 20))\n","        fig.suptitle('Regression lines for {} z-score'.format(column_name))\n","        axs[0].plot(X, y, '.m', label = '{}'.format(column_name))\n","        axs[0].set_xlabel('{}'.format(ga_at_scan_key))\n","        axs[0].set_ylabel('{}'.format(column_name))\n","        axs[0].legend()\n","        fig.tight_layout()\n","\n","        axs[0].set_axisbelow(True)\n","        axs[0].yaxis.grid(color='gray', linestyle='solid')\n","        axs[0].xaxis.grid(color='gray', linestyle='solid')\n","\n","    \n","    # Perform linear regression\n","    linear_regressor_means = LinearRegression()\n","    linear_regressor_means.fit(X, y)\n","    y_pred_means = linear_regressor_means.predict(X)\n","    coefs_means = linear_regressor_means.coef_[0]\n","    intercept_means = linear_regressor_means.intercept_\n","    \n","    if show_graphs:\n","        # Plot linear regression line for the mean\n","        y_line_function = coefs_means*X + intercept_means\n","        axs[0].plot(X, y_line_function, '-k')\n","        print('[{}] Linear regression line for the mean: y = {}*X + ({})'.format(column_name, coefs_means, intercept_means))\n","    \n","    residuals = relevant_data[column_name] - y_pred_means\n","    \n","    if show_graphs:\n","        # Plot scatterplot of the residuals vs age at scan\n","        axs[1].plot(X, residuals, '.g', label = 'residuals for term babies')\n","        axs[1].set_xlabel('{}'.format(ga_at_scan_key))\n","        axs[1].set_ylabel('{}'.format(column_name))\n","        axs[1].legend()\n","        fig.tight_layout() \n","    \n","    residuals_squared = residuals**2\n","    length = len(residuals_squared) - 1\n","    std = np.sqrt(np.sum(residuals_squared/length))\n","    #Diagonal of Hat Matrix\n","    only_diag = np.einsum('ij, ij -> j', X.T, np.linalg.pinv(X))\n","    j=0\n","\n","    for i, row in dataframe.iterrows():\n","        ga_at_scan = row[ga_at_scan_key]\n","        if (np.isnan(row[column_name])) or np.isnan(ga_at_scan):\n","            continue\n","        measurement = row[column_name]\n","        #We use the mean of 'tag_ga' column as a rough estimate of missing values\n","        if np.isnan(ga_at_scan):\n","          ga_at_scan = dataframe[ga_at_scan_key].mean()\n","        z_score = (measurement - linear_regressor_means.predict([[ga_at_scan]])) / ((std*np.sqrt(1-only_diag[j]))+epsilon)\n","        dataframe.loc[i, column_name + '_z_score'] = z_score \n","         \n","    return dataframe\n","\n","\n","def add_columns_with_z_score(dataframe, columns, show_graphs = False):\n","    for col in columns:\n","        dataframe = add_column_with_z_score(dataframe, col, show_graphs)\n","        \n","    return dataframe   "]},{"cell_type":"code","source":["epsilon = 2.22045e-16\n","def add_column_with_z_score_gu(dataframe, column_name, show_graphs):\n","    dataframe = dataframe.copy()\n","    ga_at_scan_key = 'tag_gu_ga'\n","    ga_at_delivery_key = 'tag_gadel'\n","    tech_cohort_key = 'tag_typ'\n","    \n","    if ga_at_scan_key not in dataframe:\n","        print(\"Dataframe is missing 'tag_gu_ga'(age at scan)\")\n","        return\n","    \n","    # Returns dataframe with Age at scan and specified measurement / feature\n","    relevant_data = get_columns_and_drop_nan_rows(dataframe, [ga_at_scan_key, ga_at_delivery_key, column_name, tech_cohort_key])[[ga_at_scan_key, ga_at_delivery_key, column_name, tech_cohort_key]] \n","    \n","    \n","    X = relevant_data[ga_at_scan_key].to_numpy().reshape(-1, 1)\n","    y = relevant_data[column_name]\n","    \n","    \n","    if show_graphs:\n","        # Plot scatterplot of the specific column vs age at scan\n","        fig, axs = plt.subplots(2, figsize = (20, 20))\n","        fig.suptitle('Regression lines for {} z-score_gu'.format(column_name))\n","        axs[0].plot(X, y, '.m', label = '{} for term babies'.format(column_name))\n","        axs[0].set_xlabel('{}'.format(ga_at_scan_key))\n","        axs[0].set_ylabel('{}'.format(column_name))\n","        axs[0].legend()\n","        fig.tight_layout()\n","\n","        axs[0].set_axisbelow(True)\n","        axs[0].yaxis.grid(color='gray', linestyle='solid')\n","        axs[0].xaxis.grid(color='gray', linestyle='solid')\n","\n","    \n","    # Perform linear regression\n","    linear_regressor_means = LinearRegression()\n","    linear_regressor_means.fit(X, y)\n","    y_pred_means = linear_regressor_means.predict(X)\n","    coefs_means = linear_regressor_means.coef_[0]\n","    intercept_means = linear_regressor_means.intercept_\n","    \n","    if show_graphs:\n","        # Plot linear regression line for the mean\n","        y_line_function = coefs_means*X + intercept_means\n","        axs[0].plot(X, y_line_function, '-k')\n","        print('[{}] Linear regression line for the mean: y = {}*X + ({})'.format(column_name, coefs_means, intercept_means))\n","    \n","    residuals = relevant_data[column_name] - y_pred_means\n","    \n","    if show_graphs:\n","        # Plot scatterplot of the residuals vs age at scan\n","        axs[1].plot(X, residuals, '.g', label = 'residuals for term babies')\n","        axs[1].set_xlabel('{}'.format(ga_at_scan_key))\n","        axs[1].set_ylabel('{}'.format(column_name))\n","        axs[1].legend()\n","        fig.tight_layout() \n","    \n","    \n","    residuals_squared = residuals**2\n","    length = len(residuals_squared) - 1\n","    std = np.sqrt(np.sum(residuals_squared/length))\n","    #Diagonal of Hat Matrix\n","    only_diag = np.einsum('ij, ij -> j', X.T, np.linalg.pinv(X))\n","    j=0\n","\n","    for i, row in dataframe.iterrows():\n","        ga_at_scan = row[ga_at_scan_key]\n","        if (np.isnan(row[column_name])) or np.isnan(ga_at_scan):\n","            continue\n","        measurement = row[column_name]\n","        #We use the mean of 'tag_ga' column as a rough estimate of missing values\n","        if np.isnan(ga_at_scan):\n","          ga_at_scan = dataframe[ga_at_scan_key].mean()\n","        z_score = (measurement - linear_regressor_means.predict([[ga_at_scan]])) / ((std*np.sqrt(1-only_diag[j]))+epsilon)\n","        dataframe.loc[i, column_name + '_z_score_gu'] = z_score \n","  \n","    return dataframe\n","\n","def add_columns_with_z_score_gu(dataframe, columns, show_graphs = False):\n","    for col in columns:\n","        dataframe = add_column_with_z_score_gu(dataframe, col, show_graphs)\n","        \n","    return dataframe   "],"metadata":{"id":"vV5By4qDpLSL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epsilon = 2.22045e-16\n","def add_column_with_z_score_anom(dataframe, column_name, show_graphs):\n","    dataframe = dataframe.copy()\n","    ga_at_scan_key = 'tag_anom_ga'\n","    ga_at_delivery_key = 'tag_gadel'\n","    tech_cohort_key = 'tag_typ'\n","    \n","    if ga_at_scan_key not in dataframe:\n","        print(\"Dataframe is missing 'tag_anom_ga'(age at scan)\")\n","        return\n","    \n","    # Returns dataframe with Age at scan and specified measurement / feature\n","    relevant_data = get_columns_and_drop_nan_rows(dataframe, [ga_at_scan_key, ga_at_delivery_key, column_name, tech_cohort_key])[[ga_at_scan_key, ga_at_delivery_key, column_name, tech_cohort_key]] \n","    \n","    \n","    X = relevant_data[ga_at_scan_key].to_numpy().reshape(-1, 1)\n","    y = relevant_data[column_name]\n","    \n","    \n","    if show_graphs:\n","        # Plot scatterplot of the specific column vs age at scan\n","        fig, axs = plt.subplots(2, figsize = (20, 20))\n","        fig.suptitle('Regression lines for {} z-score_gu'.format(column_name))\n","        axs[0].plot(X, y, '.m', label = '{} for term babies'.format(column_name))\n","        axs[0].set_xlabel('{}'.format(ga_at_scan_key))\n","        axs[0].set_ylabel('{}'.format(column_name))\n","        axs[0].legend()\n","        fig.tight_layout()\n","\n","        axs[0].set_axisbelow(True)\n","        axs[0].yaxis.grid(color='gray', linestyle='solid')\n","        axs[0].xaxis.grid(color='gray', linestyle='solid')\n","\n","    \n","    # Perform linear regression\n","    linear_regressor_means = LinearRegression()\n","    linear_regressor_means.fit(X, y)\n","    y_pred_means = linear_regressor_means.predict(X)\n","    coefs_means = linear_regressor_means.coef_[0]\n","    intercept_means = linear_regressor_means.intercept_\n","    \n","    if show_graphs:\n","        # Plot linear regression line for the mean\n","        y_line_function = coefs_means*X + intercept_means\n","        axs[0].plot(X, y_line_function, '-k')\n","        print('[{}] Linear regression line for the mean: y = {}*X + ({})'.format(column_name, coefs_means, intercept_means))\n","    \n","    residuals = relevant_data[column_name] - y_pred_means\n","    \n","    if show_graphs:\n","        # Plot scatterplot of the residuals vs age at scan\n","        axs[1].plot(X, residuals, '.g', label = 'residuals for term babies')\n","        axs[1].set_xlabel('{}'.format(ga_at_scan_key))\n","        axs[1].set_ylabel('{}'.format(column_name))\n","        axs[1].legend()\n","        fig.tight_layout() \n","    \n","    \n","    residuals_squared = residuals**2\n","    length = len(residuals_squared) - 1\n","    std = np.sqrt(np.sum(residuals_squared/length))\n","    #Diagonal of Hat Matrix\n","    only_diag = np.einsum('ij, ij -> j', X.T, np.linalg.pinv(X))\n","    j=0\n","\n","    for i, row in dataframe.iterrows():\n","        ga_at_scan = row[ga_at_scan_key]\n","        if (np.isnan(row[column_name])) or np.isnan(ga_at_scan):\n","            continue\n","        measurement = row[column_name]\n","        #We use the mean of 'tag_ga' column as a rough estimate of missing values\n","        if np.isnan(ga_at_scan):\n","          ga_at_scan = dataframe[ga_at_scan_key].mean()\n","        z_score = (measurement - linear_regressor_means.predict([[ga_at_scan]])) / ((std*np.sqrt(1-only_diag[j]))+epsilon)\n","        dataframe.loc[i, column_name + '_z_score_anom'] = z_score \n","         \n","    return dataframe\n","\n","\n","def add_columns_with_z_score_anom(dataframe, columns, show_graphs = False):\n","    for col in columns:\n","        dataframe = add_column_with_z_score_anom(dataframe, col, show_graphs)\n","        \n","    return dataframe   "],"metadata":{"id":"NjEOF63cV9go"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xbaeodzi9YOn"},"source":["<h2>3.2 KNN Imputation</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nB8_4BiV9YOo"},"outputs":[],"source":["def perform_imputation(dataframe):\n","    columns = dataframe.columns\n","    all_data = dataframe.values\n","    # Get indices of columns that should be taken for imputation\n","\n","    if \"plac_t2s_kurt_z_score\" in columns:\n","        plac_t2s_kurt_z_score_index = columns.get_loc(\"plac_t2s_kurt_z_score\")\n","    else:\n","        plac_t2s_kurt_z_score_index = -1\n","        print('plac_t2s_kurt_z_score NOT AVAILABLE')\n","\n","    if \"plac_t2s_lacu_z_score\" in columns:\n","        plac_t2s_lacu_z_score_index = columns.get_loc(\"plac_t2s_lacu_z_score\")\n","    else:\n","        plac_t2s_lacu_z_score_index = -1\n","        print('plac_t2s_lacu_z_score NOT AVAILABLE')\n","\n","    if \"plac_t2s_mean_z_score\" in columns:\n","        plac_t2s_mean_z_score_index = columns.get_loc(\"plac_t2s_mean_z_score\")\n","    else:\n","        plac_t2s_mean_z_score_index = -1\n","        print('plac_t2s_mean_z_score NOT AVAILABLE')  \n","\n","    if \"plac_t2s_skew_z_score\" in columns:\n","        plac_t2s_skew_z_score_index = columns.get_loc(\"plac_t2s_skew_z_score\")\n","    else:\n","        plac_t2s_skew_z_score_index = -1\n","        print('plac_t2s_skew_z_score NOT AVAILABLE')  \n","\n","    if \"plac_t2s_vol_z_score\" in columns:\n","        plac_t2s_vol_z_score_index = columns.get_loc(\"plac_t2s_vol_z_score\")\n","    else:\n","        plac_t2s_vol_z_score_index = -1\n","        print('plac_t2s_vol_z_score NOT AVAILABLE')  \n","\n","    if \"tag_cervix_length_z_score\" in columns:\n","        tag_cervix_length_z_score_index = columns.get_loc(\"tag_cervix_length_z_score\")\n","    else:\n","        tag_cervix_length_z_score_index = -1\n","        print('tag_cervix_length_z_score NOT AVAILABLE')  \n","\n","    if \"tag_age\" in columns:\n","        tag_age_index = columns.get_loc(\"tag_age\")\n","    else:\n","        tag_age_index = -1\n","        print('tag_age NOT AVAILABLE')  \n","    \n","    if \"tag_bmi\" in columns:\n","        tag_bmi_index = columns.get_loc(\"tag_bmi\")\n","    else:\n","        tag_bmi_index = -1\n","        print('tag_bmi NOT AVAILABLE')                              \n","\n","    if \"tag_loc\" in columns:\n","        tag_loc_index = columns.get_loc(\"tag_loc\")\n","    else:\n","        tag_loc_index = -1\n","        print('tag_loc NOT AVAILABLE')  \n","\n","    if \"tag_sex\" in columns:\n","        tag_sex_index = columns.get_loc(\"tag_sex\")\n","    else:\n","        tag_sex_index = -1\n","        print('tag_sex NOT AVAILABLE')  \n","\n","    if \"tag_parity\" in columns:\n","        tag_parity_index = columns.get_loc(\"tag_parity\")\n","    else:\n","        tag_parity_index = -1\n","        print('tag_parity NOT AVAILABLE')  \n","\n","    if \"tag_diabetes\" in columns:\n","        tag_diabetes_index = columns.get_loc(\"tag_diabetes\")\n","    else:\n","        tag_diabetes_index = -1\n","        print('tag_diabetes NOT AVAILABLE')  \n","\n","    if \"tag_anom_loc\" in columns:\n","        tag_anom_loc_index = columns.get_loc(\"tag_anom_loc\")\n","    else:\n","        tag_anom_loc_index = -1\n","        print('tag_anom_loc NOT AVAILABLE') \n","\n","    if \"tag_anom_cord\" in columns:\n","        tag_anom_cord_index = columns.get_loc(\"tag_anom_cord\")\n","    else:\n","        tag_anom_cord_index = -1\n","        print('tag_anom_cord NOT AVAILABLE')  \n","\n","    if \"tag_ivf\" in columns:\n","        tag_ivf_index = columns.get_loc(\"tag_ivf\")\n","    else:\n","        tag_ivf_index = -1\n","        print('tag_ivf NOT AVAILABLE')  \n","    \n","    if \"tag_smok\" in columns:\n","        tag_smok_index = columns.get_loc(\"tag_smok\")\n","    else:\n","        tag_smok_index = -1\n","        print('tag_smok NOT AVAILABLE')  \n","\n","    if \"tag_prev_ptb\" in columns:\n","        tag_prev_ptb_index = columns.get_loc(\"tag_prev_ptb\")\n","    else:\n","        tag_prev_ptb_index = -1\n","        print('tag_prev_ptb NOT AVAILABLE')  \n","\n","    if \"tag_anom_ac_z_score_anom\" in columns:\n","        tag_anom_ac_z_score_anom_index = columns.get_loc(\"tag_anom_ac_z_score_anom\")\n","    else:\n","        tag_anom_ac_z_score_anom_index = -1\n","        print('tag_anom_ac_z_score_anom NOT AVAILABLE')  \n","\n","    if \"tag_anom_bpd_z_score_anom\" in columns:\n","        tag_anom_bpd_z_score_anom_index = columns.get_loc(\"tag_anom_bpd_z_score_anom\")\n","    else:\n","        tag_anom_bpd_z_score_anom_index = -1\n","        print('tag_anom_bpd_z_score_anom NOT AVAILABLE')  \n","\n","    if \"tag_anom_fl_z_score_anom\" in columns:\n","        tag_anom_fl_z_score_anom_index = columns.get_loc(\"tag_anom_fl_z_score_anom\")\n","    else:\n","        tag_anom_fl_z_score_anom_index = -1\n","        print('tag_anom_fl_z_score_anom NOT AVAILABLE')  \n","\n","\n","    if \"tag_anom_hc_z_score_anom\" in columns:\n","        tag_anom_hc_z_score_anom_index = columns.get_loc(\"tag_anom_hc_z_score_anom\")\n","    else:\n","        tag_anom_hc_z_score_anom_index = -1\n","        print('tag_anom_hc_z_score_anom NOT AVAILABLE')  \n","\n","\n","    #THESE ONES WON'T BE IMPUTED BUT ADDED LATER\n","\n","    if \"tag_complete_id\" in columns:\n","        tag_complete_id_index = columns.get_loc(\"tag_complete_id\")\n","    else:\n","        tag_complete_id_index = -1\n","        print('tag_complete_id NOT AVAILABLE')  \n","\n","    if \"ga_delivery_4_category\" in columns:\n","        ga_delivery_4_category_index = columns.get_loc(\"ga_delivery_4_category\")\n","    else:\n","        ga_delivery_4_category_index = -1\n","        print('ga_delivery_4_category NOT AVAILABLE')  \n","\n","    if \"ga_delivery_binary_category\" in columns:\n","        ga_delivery_binary_category_index = columns.get_loc(\"ga_delivery_binary_category\")\n","    else:\n","        ga_delivery_binary_category_index = -1\n","        print('ga_delivery_binary_category NOT AVAILABLE')  \n","\n","    if \"35_and_37_category\" in columns:\n","        help_35_and_37_category_index = columns.get_loc(\"35_and_37_category\")\n","    else:\n","        help_35_and_37_category_index = -1\n","        print('35_and_37_category NOT AVAILABLE')\n","\n","    if \"tag_gadel\" in columns:\n","        tag_gadel_index = columns.get_loc(\"tag_gadel\")\n","\n","    if \"tag_ga\" in columns:\n","        tag_ga_index = columns.get_loc(\"tag_ga\")\n","\n","    if \"tag_anom_ga\" in columns:\n","        tag_anom_ga_index = columns.get_loc(\"tag_anom_ga\")\n","\n","\n","    # Array of all columns except for GA at delivery and the columns with no meaning (id of patients etc)\n","    ix = [i for i in range(all_data.shape[1]) if (i == plac_t2s_kurt_z_score_index or \n","                                                  i == plac_t2s_lacu_z_score_index or\n","                                                  i == plac_t2s_mean_z_score_index or\n","                                                  i == plac_t2s_skew_z_score_index or\n","                                                  i == plac_t2s_vol_z_score_index or\n","                                                  i == tag_cervix_length_z_score_index or\n","                                                  i == tag_age_index or \n","                                                  i == tag_bmi_index or\n","                                                  i == tag_loc_index or\n","                                                  i == tag_sex_index or\n","                                                  i == tag_parity_index or\n","                                                  i == tag_diabetes_index or\n","                                                  i == tag_anom_loc_index or\n","                                                  i == tag_anom_cord_index or\n","                                                  i == tag_ivf_index or\n","                                                  i == tag_smok_index or\n","                                                  i == tag_prev_ptb_index or\n","                                                  i == tag_anom_ac_z_score_anom_index or\n","                                                  i == tag_anom_bpd_z_score_anom_index or\n","                                                  i == tag_anom_fl_z_score_anom_index or\n","                                                  i == tag_anom_hc_z_score_anom_index)]\n","    \n","    X = all_data[:, ix] # Features are all rows of relevant columns\n","    y = all_data[:, tag_gadel_index] # Labels are GA at delivery\n","    \n","    # define imputer\n","    #Other options:            estimator=KNeighborsRegressor(weights='distance'),\n","    imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=1),\n","                               initial_strategy='mean', \n","                               max_iter=10, random_state=1,\n","                               verbose=11)\n","    # fit on the dataset\n","    Xtrans = imputer.fit_transform(X)\n","        \n","    df_imputation = pd.DataFrame(Xtrans)\n","    \n","    # Take only column names from indices which were used for continuous imputation\n","    col_names_for_imputation = columns[ix]\n","    \n","    # Assign the correct column name for the imputated cols\n","    df_imputation.columns = col_names_for_imputation\n","\n","    #Round categorical values to nearest integer\n","    df_imputation = df_imputation.round({\"tag_loc\": 0,\n","                                         \"tag_sex\": 0,\n","                                         \"tag_parity\": 0,\n","                                         \"tag_prev_ptb\": 0,\n","                                         \"tag_diabetes\": 0,\n","                                         \"tag_anom_loc\": 0,\n","                                         \"tag_anom_cord\": 0,\n","                                         \"tag_smok\": 0,\n","                                         \"tag_ivf\": 0})\n","\n","    # Insert back important columns that were not imputated\n"," \n","    if \"tag_gadel\" in columns:\n","        df_imputation.insert(loc = 0, column = columns[tag_gadel_index], value = y)\n","\n","    if \"tag_complete_id\" in columns:\n","        df_imputation.insert(loc = 0, column = columns[tag_complete_id_index], value = all_data[:, tag_complete_id_index])\n","\n","    if \"ga_delivery_4_category\" in columns:\n","        df_imputation.insert(loc = 0, column = columns[ga_delivery_4_category_index], value = all_data[:, ga_delivery_4_category_index])\n","\n","    if \"ga_delivery_binary_category\" in columns:\n","        df_imputation.insert(loc = 0, column = columns[ga_delivery_binary_category_index], value = all_data[:, ga_delivery_binary_category_index])\n","\n","    if \"35_and_37_category\" in columns:\n","        df_imputation.insert(loc = 0, column = columns[help_35_and_37_category_index], value = all_data[:, help_35_and_37_category_index]) \n","\n","        \n","    return df_imputation\n"]},{"cell_type":"markdown","metadata":{"id":"7g4KaW239YOo"},"source":["<h2>3.3 Apply Z-Score and KNN imputation</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C_bMI6629YOo"},"outputs":[],"source":["_data_with_z_scores = add_columns_with_z_score(get_data(), ALL_Z_SCORE_FEATURE_NAMES, False)\n","\n","def get_data_with_z_scores():\n","    return _data_with_z_scores.copy()\n","\n","_data_with_z_scores_gu = add_columns_with_z_score_gu(get_data_with_z_scores(), ALL_Z_SCORE_FEATURE_NAMES_GU, False)\n","\n","def get_data_with_z_scores_gu():\n","    return _data_with_z_scores_gu.copy()\n","    \n","_data_with_z_scores_anom = add_columns_with_z_score_anom(get_data_with_z_scores_gu(), ALL_Z_SCORE_FEATURE_NAMES_ANOM, False)\n","\n","def get_data_with_z_scores_anom():\n","    return _data_with_z_scores_anom.copy()\n","\n","def get_processed_data():\n","    data = get_data()\n","    data = add_columns_with_z_score(data, ALL_Z_SCORE_FEATURE_NAMES) \n","    data = add_columns_with_z_score_gu(data, ALL_Z_SCORE_FEATURE_NAMES_GU)\n","    data = add_columns_with_z_score_anom(data, ALL_Z_SCORE_FEATURE_NAMES_ANOM)\n","    data = perform_imputation(data)\n","    \n","    return data.copy()"]},{"cell_type":"markdown","metadata":{"id":"9YUTPnT_9YOo"},"source":["<h1>4. Feature Selection for model training</h1>"]},{"cell_type":"markdown","metadata":{"id":"AUTCmUT59YOo"},"source":["<h2>4.1 Helper functions for feature selection</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LkQ2eKjd9YOp"},"outputs":[],"source":["def get_missing_data_info(print_missing = False):\n","    dataframe = get_data()\n","    col_names_with_values = []\n","    nr_of_rows = dataframe.shape[0]\n","    \n","    missing_values_info = {}\n","\n","    for i in range(dataframe.shape[1]):\n","        array = dataframe.iloc[:, i].values\n","        nr_of_NaN = np.count_nonzero(np.isnan(array))\n","        col_names_with_values.append(dataframe.columns[i])\n","        \n","        # Find percentage of missing values\n","        percentage_of_missing_vals = round((nr_of_NaN / nr_of_rows)*100, 2)\n","        \n","        missing_values_info[dataframe.columns[i]] = percentage_of_missing_vals\n","        # missing_values_info[dataframe.columns[i] + '_z_score'] = percentage_of_missing_vals\n","            \n","        # Count number of rows with missing values\n","        if print_missing:\n","            print('> %d, %s, Missing: %d (%.1f%%)' % (i, dataframe.columns[i], nr_of_NaN, percentage_of_missing_vals))\n","\n","    return missing_values_info\n","\n","get_missing_data_info(print_missing = False)"]},{"cell_type":"markdown","metadata":{"id":"qk1s_IEE9YOp"},"source":["<h2>4.2 Feature selection related functions</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vO9Bho9x9YOp"},"outputs":[],"source":["def get_feature_importances(data):\n","    # generate dataset\n","    X = data[ALL_FEATURE_NAMES]\n","    y = data['tag_gadel'].ravel()\n","    # define feature selection\n","    #fs = SelectKBest(score_func=f_regression, k=\"all\")\n","    fs = SelectFromModel(RandomForestRegressor(random_state=1))\n","    # apply feature selection\n","    fs.fit_transform(X, y)\n","    cols = fs.get_support(indices=True)\n","    features_df_new = X.iloc[:,cols]\n","    \n","    feature_with_scores = {}\n","    \n","    for i, feature in enumerate(ALL_FEATURE_NAMES):\n","       #feature_with_scores[feature] = fs.scores_[i]\n","        feature_with_scores[feature] = fs.estimator_.feature_importances_[i]\n","    \n","    return {k: v for k, v in sorted(feature_with_scores.items(), key=lambda item: item[1], reverse=True)}\n","\n","def get_k_best_labels_features(data, k):\n","    return [i[0] for i in list(feature_importances.items())[:k]]\n","\n","def get_k_best_feature_labels_by_importances(feature_importances, k):\n","    return [i[0] for i in list(feature_importances.items())[:k]]\n"]},{"cell_type":"markdown","metadata":{"id":"hycoBiLQ9YOp"},"source":["<h1>5. Additional logic and functions needed for model training</h1>"]},{"cell_type":"markdown","metadata":{"id":"cbfDFLXw9YOp"},"source":["<h2>5.1 Weight array calculation functions</h2>\n","<p>Following 3 functions return an array of weights, where the weighting is done in one of the 3 following ways:</p>\n","<ul>\n","    <li>1. Weighting based on week</li>\n","    <li>2. Weighting based on binary category</li>\n","    <li>3. Weighting based on 4 categories</li>\n","</ul>"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"pham2k8q9YOq"},"outputs":[],"source":["def get_weights_based_on_week():\n","    list_of_ga_at_delivery = get_data()['tag_gadel']\n","    list_of_ga_at_delivery_significant_nrs = [int(element) for element in list_of_ga_at_delivery]\n","    map_of_age_at_delivery_with_count = Counter(list_of_ga_at_delivery_significant_nrs)\n","    weights = []\n","\n","    for item in list_of_ga_at_delivery_significant_nrs:\n","        nr_of_babies_born_at_specified_time = map_of_age_at_delivery_with_count[item]\n","        weights.append(1/nr_of_babies_born_at_specified_time)\n","    return weights\n","\n","def get_weights_based_on_binary_category():\n","    list_of_ga_at_delivery = get_data()['ga_delivery_binary_category']\n","    list_of_ga_at_delivery_2_significant_nrs = [element for element in list_of_ga_at_delivery]\n","    map_of_age_at_delivery_with_count = Counter(list_of_ga_at_delivery_2_significant_nrs)\n","    weights = []\n","\n","    for item in list_of_ga_at_delivery_2_significant_nrs:\n","        nr_of_babies_born_at_specified_time = map_of_age_at_delivery_with_count[item]\n","        weights.append(1/nr_of_babies_born_at_specified_time)\n","    return weights\n","\n","def get_weights_based_on_4_category():\n","    list_of_ga_at_delivery = get_data()['ga_delivery_4_category']\n","    list_of_ga_at_delivery_4_significant_nrs = [element for element in list_of_ga_at_delivery]\n","    map_of_age_at_delivery_with_count = Counter(list_of_ga_at_delivery_4_significant_nrs)\n","    weights = []\n","\n","    for item in list_of_ga_at_delivery_4_significant_nrs:\n","        nr_of_babies_born_at_specified_time = map_of_age_at_delivery_with_count[item]\n","        weights.append(1/nr_of_babies_born_at_specified_time)\n","    return weights"]},{"cell_type":"markdown","metadata":{"id":"GvGweRTy9YOq"},"source":["<h2>5.2 Machine learning models</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlPegHAR9YOq"},"outputs":[],"source":["def get_polynomial_ridge_model():\n","    model = Pipeline(((\"poly_features\", PolynomialFeatures(include_bias = False)), (\"ridge\", Ridge()) ))\n","    parameters = {\"poly_features__degree\": range(1, 10), \"ridge__alpha\": np.logspace(-6, 6, 20)}\n","    \n","    return (model, parameters, 'Polynomial ridge model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pg-FRCNw9YOq"},"outputs":[],"source":["def get_polynomial_lasso_model():\n","    model = Pipeline(((\"poly_features\", PolynomialFeatures(include_bias = False)), (\"lasso\", Lasso()) ))\n","    parameters = {\"poly_features__degree\": range(1, 10), \"lasso__alpha\": np.logspace(-6, 6, 20)}\n","    \n","    return (model, parameters, 'Polynomial lasso model') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhRV-xmG9YOq"},"outputs":[],"source":["def get_svr_model():\n","    model = Pipeline([(\"svr\", SVR(max_iter=1000000))])\n","    parameters = {'svr__C': [0.1,1, 10, 100], 'svr__gamma':[1,0.1,0.01,0.001],'svr__kernel': ['rbf', 'poly', 'sigmoid', 'linear'], 'svr__epsilon': [0.1, 0.5, 1, 1.5], 'svr__degree': [2, 3]}\n","    return (model, parameters, 'SVR model')"]},{"cell_type":"code","source":["def get_rf_model():\n","    model = Pipeline([(\"rf\", RandomForestRegressor(n_jobs=-1, random_state=1))])\n","    parameters = {'rf__max_depth': [3, 5, 10, 20, 50, 100], \n","                  'rf__max_features': ['auto', 'sqrt', 'log2'],\n","                  'rf__n_estimators': [10,20,50,100, 250]}\n","    return (model, parameters, 'RF model')"],"metadata":{"id":"r1sepFkOpQFE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3DeXgDZf9YOr"},"source":["<h1>6. Model training and choosing the best model</h1>"]},{"cell_type":"markdown","metadata":{"id":"sko4m3ox9YOr"},"source":["<h2>6.1 Main function to train and evaluate a model</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8J88t7Op9YOr"},"outputs":[],"source":["def get_stats_per_model(X, labels, model_pipeline, model_parameters, stratification_type, random_state, cv_folds):\n","    X = X.values\n","    if (stratification_type is not False):\n","        X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size = 0.2, stratify=stratification_type, random_state = random_state ) \n","    else:\n","        X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size = 0.2, random_state = random_state ) \n","    \n","    grid_search = GridSearchCV(model_pipeline, model_parameters, cv = cv_folds, scoring = 'r2', verbose = 11, n_jobs=-1)\n","\n","    scaler = StandardScaler()\n","\n","    weights = X_train[:, -1]\n","    weights = weights.copy(order='C')\n","\n","    X_train = X_train[:, 0:-1]\n","    X_test = X_test[:, 0:-1]\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","\n","\n","    grid_search.fit(X_train, y_train)\n","    best_model_params = grid_search.best_params_\n","\n","    y_pred = grid_search.predict(X_test)\n","\n","    y_true = y_test.reshape(-1)\n","    r2 = r2_score(y_true, y_pred)\n","    \n","    mean_error = mean_absolute_error(y_true, y_pred)\n","    \n","    return r2, mean_error, best_model_params"]},{"cell_type":"markdown","metadata":{"id":"qtA4Dzd99YOr"},"source":["<h2>6.2 Main loop</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tpjggl159YOr"},"outputs":[],"source":["output_file_path = '/path/'\n","\n","# Stratification\n","labels_binary_classification = get_data()['ga_delivery_binary_category'].to_numpy()\n","labels_4_cat = get_data()['ga_delivery_4_category'].to_numpy()\n","labels_35_37_cat = get_data()['35_and_37_category'].to_numpy()\n","\n","warnings.filterwarnings('ignore')\n","# stratification_variations = [\n","#     (labels_35_37_cat, '35_and_37_cat'),\n","#     (labels_binary_classification, 'binary_cat'),\n","#     (labels_4_cat, '4_cat')]\n","\n","stratification_variations = [(labels_binary_classification, 'binary_cat')]\n","\n","def try_different_combinations(feature_labels, nr_of_features_to_try, weights = get_weights_based_on_week()):\n","    \n","    # Create the time-stamped file for when the function is run\n","    time_str = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n","    f = open(output_file_path + '/resultsML_'+ time_str +'.tsv', 'w+')\n","             #get_rf_model()\n","    models = [get_svr_model()] # Add models to be tested\n","    \n","    data = get_processed_data()\n","    labels = data['tag_gadel'].values.reshape(-1, 1)\n","    labels = labels.ravel()\n","    \n","    headers = ['Model', 'Parameters', 'Combination', 'Stratified', 'CV folds', 'Random state', 'R-score', 'Mean error']\n","    header_row = '\\t'.join(headers) + '\\n'\n","    f.write(header_row)\n","\n","    for (stratification, startification_description) in stratification_variations:\n","        for cv_folds in [5]:\n","            for random_state in [1]:\n","                for model in models:\n","                    for nr_of_features in nr_of_features_to_try:\n","                        combinations = list(itertools.combinations(feature_labels, nr_of_features))   \n","                        for combination in combinations:      \n","                            execute_calculation(data,\n","                                                combination,\n","                                                labels,\n","                                                model[0],\n","                                                model[1],\n","                                                model[2],\n","                                                stratification,\n","                                                startification_description,\n","                                                random_state,\n","                                                cv_folds,\n","                                                weights,\n","                                                f)\n","    print('Finished!')      \n","                            \n","def execute_calculation(data,\n","                        combination, \n","                        labels,  \n","                        model, \n","                        model_parameters,\n","                        model_description,\n","                        stratification,\n","                        stratification_description,\n","                        random_state,\n","                        cv_folds,\n","                        weights,\n","                        f):\n","    features_comb = data[list(combination)]\n","    # Add weights to features\n","    features_comb['weights'] = pd.Series(weights, index = features_comb.index)\n","\n","    (r2, mean_error, best_model_params) = get_stats_per_model(\n","        features_comb, \n","        labels, \n","        model, \n","        model_parameters, \n","        stratification, \n","        random_state, \n","        cv_folds)\n","\n","    result = '\\t'.join([str(model_description), str(best_model_params), str(combination), str(stratification_description), str(cv_folds), str(random_state), str(r2), str(mean_error)])\n","    \n","    f.write(result + '\\n')\n","    f.flush()"]},{"cell_type":"markdown","metadata":{"id":"5eK9yI-S9YOr"},"source":["<h1>6.3 Visualisation functions</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B3ylzD349YOr"},"outputs":[],"source":["def save_fig(fileName, plt):\n","    plt.savefig('/path/Images/{}.jpg'.format(fileName), bbox_inches='tight', dpi=250)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5MsMKzQ39YOr"},"outputs":[],"source":["# Function for plotting the data\n","'''\n","x_data: Data used for x-axis of the plot\n","y_data: Data used for y-axis of the plot\n","categories_data: Data used for coloring markers per category\n","nr_of_categories: Number of categories that should be in data (either 2 or 4)\n","visible_categories: By default all categories are shown. If specified by integer array, only those will be shown\n","'''\n","\n","def plot_data(x_data, y_data, categories_data, category_labels, xlabel, ylabel,graph_title, plot_line_of_best_fit):\n","    fig, ax = plt.subplots(figsize=(20,15))\n","    lines_of_best_fit_labels = []\n","    legend = []\n","\n","    # Marker configuration\n","    m = ['.','d', '^', 'X', '.', 'd', '^', 'X']\n","    markercolor = COLORS\n","    marker_size = 17    \n","    \n","    for k, category_label in enumerate(category_labels):\n","        # Pick the right values\n","        x_vals = x_data[categories_data==k]\n","        y_vals = y_data[categories_data==k]\n","        # Remove vals where y-value is NaN and make x and y the same size\n","        x_vals = x_vals[~np.isnan(y_vals)]\n","        y_vals = y_vals[~np.isnan(y_vals)]\n","        plt.plot(x_vals, y_vals, m[k], alpha=1, markerfacecolor = markercolor[k], markersize = marker_size, markeredgecolor = 'k', markeredgewidth = 0.5)\n","        legend.append(category_label)\n","        if plot_line_of_best_fit:\n","            slope, intercept = np.polyfit(x_vals, y_vals, 1)\n","            plt.plot(x_vals, slope*x_vals + intercept, linestyle='solid', color=markercolor[k], linewidth = 3)\n","            print('slope:', slope, category_label)\n","            print('intercept', intercept, category_label)\n","            legend.append(category_label + ' line of best fit')\n","            \n","\n","    plt.legend(legend, prop={'size': 20}, loc = 'upper left')  \n","        \n","    plt.title('Diagnosis of preterm birth')\n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","    plt.title(graph_title)\n","    plt.rcParams.update({'font.size': 30})    \n"," \n","    \n","    # Add grid behind plot\n","    ax.grid()\n","    ax.set_axisbelow(True)\n","    ax.minorticks_on()\n","    ax.grid(which='major', linestyle=':', linewidth='0.5', color='black')\n","    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n","    \n","    save_fig(graph_title, plt)\n","    "]},{"cell_type":"code","source":["#Function for plotting predictions and dividing them according to preterm birth temporal categories\n","\n","def plot_data_identity(x_data, y_data, categories_data, category_labels, xlabel, ylabel,graph_title, plot_line_of_best_fit, identity):\n","    fig, ax = plt.subplots(figsize=(15,15))\n","    lines_of_best_fit_labels = []\n","    legend = []\n","\n","    # Marker configuration\n","    m = ['.','.', '.', '.', '.', 'd', '^', 'X']\n","    markercolor = COLORS\n","    marker_size = 17    \n","    \n","    for k, category_label in enumerate(category_labels):\n","        # Pick the right values\n","        x_vals = x_data[categories_data==k]\n","        y_vals = y_data[categories_data==k]\n","        # Remove vals where y-value is NaN and make x and y the same size\n","        x_vals = x_vals[~np.isnan(y_vals)]\n","        y_vals = y_vals[~np.isnan(y_vals)]\n","        plt.plot(x_vals, y_vals, m[k], alpha=1, markerfacecolor = markercolor[k], markersize = marker_size, markeredgecolor = 'k', markeredgewidth = 0.5)\n","        legend.append(category_label)\n","        if plot_line_of_best_fit:\n","            slope, intercept = np.polyfit(x_vals, y_vals, 1)\n","            plt.plot(x_vals, slope*x_vals + intercept, linestyle='solid', color=markercolor[k], linewidth = 3)\n","            print('slope:', slope, category_label)\n","            print('intercept', intercept, category_label)\n","            legend.append(category_label + ' line of best fit')\n","            \n","\n","    plt.legend(legend, prop={'size': 25}, loc = 'upper left')  \n","    \n","    \n","    #Add identity line\n","    if identity:\n","      plt.plot( [20,42],[20,42], linewidth = 3) \n","      legend.append('identity line')\n","        \n","    plt.title('Diagnosis of preterm birth')\n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","    plt.title(graph_title)\n","    plt.rcParams.update({'font.size': 30})   \n","    \n"," \n","    \n","    major_ticks = [20,22,24,26,28,30,32,34,37,40,42]\n","    \n","    # Add grid behind plot\n","    ax.grid()\n","    ax.axis('equal')\n","    ax.set_xticks(major_ticks)\n","    ax.set_yticks(major_ticks)\n","    ax.set_axisbelow(True)\n","    ax.minorticks_on()\n","    ax.xaxis.set_minor_locator(MultipleLocator(1))\n","    ax.yaxis.set_minor_locator(MultipleLocator(1))\n","    ax.grid(which='major', linestyle=':', linewidth='0.5', color='black')\n","    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n","    a = ax.get_ygridlines() \n","    b = a[8]\n","    b.set_color('red')\n","    b.set_linewidth(3)\n","    c = a[6]\n","    c.set_color('green')\n","    c.set_linewidth(3)\n","    d = a[4]\n","    d.set_color('orange')\n","    d.set_linewidth(3)\n","    \n","    \n","    save_fig(graph_title, plt)"],"metadata":{"id":"S3TR_Axrm11q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NcQ6nQmI9YOs"},"source":["<h1>7. Model analysis functions</h1>\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_DQR4J_9YOs"},"outputs":[],"source":["# Function to manually try the best outcomes, need to specify the hyperparameters\n","def try_best_from_comb(feature_labels):\n","   #model = SVR(C = 100, degree = 2, gamma = 0.01, epsilon=0.1, kernel = 'rbf', max_iter=1000000)\n","    model = RandomForestRegressor(n_estimators=50, max_depth=20, max_features='sqrt', random_state=1)\n","    data_to_use = get_processed_data()\n","    # Add weights column\n","    data_to_use['weights'] = pd.Series(get_weights_based_on_binary_category(), index = data_to_use.index)\n","    \n","    features_and_weight_labels = feature_labels + ['weights']\n","    \n","    features =  data_to_use[features_and_weight_labels]\n","\n","    \n","    y = data_to_use['tag_gadel'].values.reshape(-1, 1)\n","    y = y.ravel()\n","    \n","    scaler = StandardScaler()\n","    weight_label_index = features.shape[1] - 1\n","\n","    X_train, X_test, y_train, y_test = train_test_split(features, y, test_size = 0.2, stratify=labels_binary_classification, random_state = 1) \n","\n","    weights = X_train['weights']\n","    X_train = X_train[features_and_weight_labels[: weight_label_index]]\n","    X_test = X_test[features_and_weight_labels[: weight_label_index]]\n","\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    # model.fit(X_train, y_train, sample_weight = weights)\n","    model.fit(X_train, y_train)\n","    \n","    \n","    y_pred = model.predict(X_test)\n"," \n","    y_true = y_test\n","    r2 = r2_score(y_true, y_pred)\n","    print('R2 is: {}'.format(r2))\n","    mean_abs = mean_absolute_error(y_true, y_pred)\n","    print('MEAN ABS is: {}'.format(mean_abs))\n","    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n","    print('RMSE is: {}'.format(rmse))\n","    \n","    \n","    \n","    results_df = pd.DataFrame({'real_values':y_true, 'predicted_values':y_pred})\n","\n","    svr_df = divide_to_categories(results_df, ['real_values', 'predicted_values'], ['real_values', 'predicted_values'])\n","    \n","    if (SHOW_VISUALISATIONS):\n","        plot_data_identity(y_true, y_pred, svr_df['real_values_4_category'], BIRTH_CATEGORIES_4, 'True GA at birth (weeks)', 'Predicted GA at birth (weeks)', 'Predicted GA by the best SVR model vs true GA', False, True)\n","\n","    return svr_df"]},{"cell_type":"markdown","source":["<h1>7.1 Function for evaluating the classification task</h1>"],"metadata":{"id":"Yf5xlJ_vvRRL"}},{"cell_type":"code","source":["#Function to evaluate the classification predictions of the best models\n","def evaluation(y, y_pred):\n","    # accuracy\n","    acc = accuracy_score(y, y_pred)\n","    print('accuracy: ', round(acc,2))\n","    # default is sensitivity: pos_label = 1\n","    sensitivity = recall_score(y,y_pred)\n","    print('sensitivity: ',round(sensitivity,2))\n","    # pos_label = 0 gives specificity\n","    specificity = recall_score(y,y_pred,pos_label = 0)\n","    print('specificity: ',round(specificity,2))"],"metadata":{"id":"xjQqO02Fug9n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"378ifBkV9YOt"},"source":["<h1>8. Data exploration and visualisation functions</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALt28esd9YOt"},"outputs":[],"source":["# Funtion to print out characteristics of a feature\n","def get_characteristics_of_feature(feature, feature_name, x_label, y_label, title = 'Histogram',display_graph = False):\n","    data = get_data()\n","    # Count how many instances do not have a value\n","    array = data[feature_name].values\n","    nr_of_NaN = np.count_nonzero(np.isnan(array))\n","    \n","    # Find percentage of missing values\n","    nr_of_rows = data[feature_name].size\n","    percentage_of_missing_vals = round((nr_of_NaN / nr_of_rows)*100, 2)\n","    print('These are the characteristics of feature {}:'.format(feature_name))\n","    print('{}% of values are missing.'.format(percentage_of_missing_vals))\n","\n","    # Find the variance\n","    variance = np.nanvar(array) \n","    print('Variance is: {}.'.format(round(variance, 3)))\n","    \n","    fig, ax = plt.subplots()\n","    \n","    if display_graph:\n","        # Plot histogram\n","        if (len(set(array)) == 2):\n","            nr_of_bins = 2\n","        else:\n","            nr_of_bins = 15\n","\n","        counts, bins, patches = ax.hist(array, nr_of_bins, density=False, histtype='bar', facecolor='#003f5c', ec='black')\n","\n","        ax.set_xlabel(x_label)\n","        ax.set_ylabel(y_label)\n","        ax.set_xticks(bins)\n","        ax.set_xticklabels(ax.get_xticks(), rotation = 45)\n","        ax.set_title(title)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvvaK5T99YOt"},"outputs":[],"source":["def count_instances_per_category(catecory_column_name):\n","    categories_data_new = get_data()[catecory_column_name]\n","    unique_new, counts_new = np.unique(categories_data_new, return_counts=True)\n","    return dict(zip(unique_new, counts_new)) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XuUSX6Zg9YOu"},"outputs":[],"source":["def plot_histogram(values, x_label, y_label, title, x_step = 2, y_step = 2):\n","    minBin = int(min(values))\n","    maxBin = int(math.ceil(max(values))) + 2\n","    counts, bins, patches = plt.hist(values, np.arange(minBin, maxBin) - 0.5, density=False, histtype='bar', facecolor='#2f4b7c', ec='black')\n","    \n","    plt.xlabel(x_label, fontsize=18, labelpad=15)\n","    plt.ylabel(y_label, fontsize=18, labelpad=15)\n","    plt.title(title, fontsize=18)\n","\n","    plt.xticks(np.arange(minBin, maxBin, x_step), rotation=90, fontsize = 14)\n","    plt.yticks(np.arange(0,max(counts) + 2, y_step), fontsize=14)\n","    \n","    save_fig(title, plt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIR1yvc69YOu"},"outputs":[],"source":["def first_digit(num):\n","    return int(str(num)[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0Kl-29E9YOu"},"outputs":[],"source":["def draw_pie_chart(list_of_nrs, labels):\n","    unique_new, counts_new = np.unique(list_of_nrs, return_counts=True)\n","    dict_of_study_participants = dict(zip(unique_new, counts_new))\n","    print(dict_of_study_participants)\n","    list_of_participant_per_study = list(dict_of_study_participants.values())\n","\n","    study_labels = labels\n","    colors = COLORS\n","    fig1, ax1 = plt.subplots(figsize=(25,15))\n","    patches, texts, autotexts = ax1.pie(list_of_participant_per_study, colors = colors, startangle=180, autopct='%1.1f%%')\n","    plt.legend(study_labels, loc=\"best\", prop={'size': 26})\n","    plt.axis('equal')\n","\n","    for autotext in autotexts:\n","        autotext.set_color('white')\n","        autotext.set_size(25)\n","        autotext.set_weight('bold')\n","\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0lYoXuc9YOu"},"outputs":[],"source":["def generate_latex_table():\n","    # Descriptive statistics on the whole dataset before imputation\n","    original_data = get_data()\n","    all_col_names = original_data.columns\n","    nr_of_rows = original_data.shape[0]\n","    \n","    all_skews = original_data.skew(axis = 'index')\n","    all_means = original_data.mean(axis = 'index')\n","    all_medians = original_data.median(axis = 'index')\n","    all_std = original_data.std(axis = 'index')\n","    \n","    for i in range(0, len(all_skews)):\n","        array = original_data.iloc[:, i].values\n","        nr_of_NaN = np.count_nonzero(np.isnan(array))\n","        # Find percentage of missing values\n","        percentage_of_missing_vals = round((nr_of_NaN / nr_of_rows)*100, 2)\n","\n","        print('$',all_col_names[i],'$','&', nr_of_NaN,'('+str(percentage_of_missing_vals)+'\\%)','&', round(all_means[i],2), '&', round(all_medians[i],2), '&', round(all_std[i],2), '&', round(all_skews[i],2),\"\\\\\\\\\")\n","        print(\"\\hline\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPT4opoP9YOv"},"outputs":[],"source":["# Plot important features\n","def plot_important_features():\n","    data = get_data()\n","    features_to_plot = ['brain_t2s_vol', 'tag_bpd', 'tag_gu_hc']\n","    nr_of_features = len(features_to_plot)\n","    nr_of_cols = 1\n","\n","\n","    # Find how many rows are needed\n","    nr_of_rows = nr_of_features // nr_of_cols\n","    nr_of_rows += nr_of_features % nr_of_cols\n","\n","    subplot_index = range(1, nr_of_features + 1)\n","\n","\n","    fig = plt.figure(1)\n","    fig.set_figheight(15)\n","    fig.set_figwidth(20)\n","\n","    for i, tag in enumerate(features_to_plot):\n","        ax = fig.add_subplot(nr_of_rows, nr_of_cols, subplot_index[i])\n","        y_vals = data[tag]\n","        ax.plot(data['tag_ga'], y_vals, 'ob', color = '#2f4b7c')\n","        ax.set_xlabel('Gestational Age at Scan (weeks)')\n","        ax.set_ylabel(tag)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bssDlC_-9YOy"},"outputs":[],"source":["sorted_dict_feature_importances = dict(sorted(feature_importances.items(), key=lambda item: item[1], reverse=True))\n","\n","sorted_list_feature_importance_keys = list(sorted_dict_feature_importances.keys())\n","sorted_list_feature_importance_values = list(sorted_dict_feature_importances.values())\n","\n","print(sorted_list_feature_importance_keys)\n","\n","if SHOW_VISUALISATIONS:\n","    plt.figure(figsize = (20, 15))\n","    plt.bar(sorted_list_feature_importance_keys[0:20],sorted_list_feature_importance_values[0:20], color = '#f95d6a', edgecolor ='black')\n","    plt.xlabel('Feature name', fontsize=24, labelpad=15)\n","    plt.ylabel('Feature importance (arb. units)', fontsize=24, labelpad=15)\n","    plt.title('Top 20 features selected by $\\it{SelectFromModel}$ with importances model $\\it{Insert Model}$', fontsize=24)\n","\n","    plt.xticks(rotation=90, fontsize = 18)\n","    plt.yticks(fontsize=18)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"PredictingGestationalAgeAtBirth.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}